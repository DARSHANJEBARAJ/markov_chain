{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoitbMhxVU-5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install markovify\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import markovify\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import gutenberg"
      ],
      "metadata": {
        "id": "x_HBu7KrsHnp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "selected_text = 'austen-emma.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt5FRwFcsIX4",
        "outputId": "0287f5a9-ed34-48da-e5c1-bad51bf518d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s.,;!?]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "raw_text = gutenberg.raw(selected_text)\n",
        "cleaned_text = preprocess(raw_text)"
      ],
      "metadata": {
        "id": "9pD8_sg_sLkF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = markovify.Text(cleaned_text, state_size=2)"
      ],
      "metadata": {
        "id": "myqhOy8BsMPm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limit_sentence_words(sentence, max_words=15):\n",
        "    words = sentence.split()\n",
        "    return ' '.join(words[:max_words])"
      ],
      "metadata": {
        "id": "2KjZMbFOsSW7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated sentences:\")\n",
        "for i in range(5):\n",
        "    sentence = model.make_sentence(tries=100)\n",
        "    if sentence:\n",
        "        sentence = limit_sentence_words(sentence, max_words=15)\n",
        "        print(f\"{i+1}. {sentence}\")\n",
        "    else:\n",
        "        print(f\"{i+1}. Unable to generate a sentence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t8rPpdgqTzV",
        "outputId": "4da959fb-25b6-45ce-ab56-c6f2625ebad8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentences:\n",
            "1. , and refrained from any draught of air can find its way unpermitted . weather\n",
            "2. , as no remembrances , even in memory , is either reading to himself ,\n",
            "3. , and she was sorry on his own daughters marrying , nor any ambition beyond\n",
            "4. , knightley , but in vain . emma listened , were coming , i will\n",
            "5. , in such a dread of being nursed by mrs. weston , if not wise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model_filename = \"/content/markov_model.pkl\"\n",
        "with open(model_filename, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBI752EIun-u",
        "outputId": "ae3e4853-ac0e-496e-c914-a5816dbcef4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as /content/markov_model.pkl\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}